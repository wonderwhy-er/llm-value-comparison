<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Methodology - LLM Value Comparison</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500;600;700&display=swap');
        body {
            background: #0a0a0f;
            color: #e0e0e0;
            font-family: 'JetBrains Mono', monospace;
            line-height: 1.6;
            padding: 3rem 1rem;
            max-width: 800px;
            margin: 0 auto;
        }
        h1 { color: #00ff88; border-bottom: 2px solid #00ff88; padding-bottom: 0.5rem; }
        h2 { color: #ffc800; margin-top: 2rem; }
        .card {
            background: rgba(255,255,255,0.03);
            border: 1px solid rgba(255,255,255,0.1);
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }
        code { background: #1a1a2e; color: #ff6b6b; padding: 0.2rem 0.4rem; border-radius: 4px; }
        a { color: #88f; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .back-link { display: inline-block; margin-bottom: 2rem; color: #00ff88; }
        table { width: 100%; border-collapse: collapse; margin: 1rem 0; font-size: 0.85rem; }
        th { background: rgba(0,255,136,0.1); text-align: left; padding: 0.75rem; color: #00ff88; }
        td { padding: 0.75rem; border-bottom: 1px solid rgba(255,255,255,0.05); }
    </style>
</head>
<body>
    <a href="../index.html" class="back-link">‚Üê Back to Calculator</a>
    
    <h1>üìê Subscription Estimation Methodology</h1>
    <p>Because AI providers (OpenAI, Anthropic, Google) do not publish exact daily token budgets for their "unlimited" or "message-capped" plans, this project uses an empirical estimation model based on 2025/2026 research.</p>

    <div class="card">
        <h2>1. The "Turn" Standard (6,400 Tokens)</h2>
        <p>We standardize a single "message" or "turn" at <strong>6,400 tokens</strong>.</p>
        <ul>
            <li><strong>Source:</strong> <a href="https://a16z.com/state-of-ai/" target="_blank">OpenRouter 2025 State of AI Report</a></li>
            <li><strong>Why:</strong> Based on a study of 100 trillion real-world tokens, the average prompt length has quadrupled to ~6,000 tokens while completions average ~400 tokens. This reflects modern "context-heavy" usage like coding and agentic workflows.</li>
        </ul>
    </div>

    <div class="card">
        <h2>2. Capacity Scaling (The 10x Rule)</h2>
        <p>We use a <strong>10x capacity multiplier</strong> to estimate "Unlimited" or "Pro" tiers compared to "Plus" tiers.</p>
        <ul>
            <li><strong>Logic:</strong> OpenAI provides exactly 10x capacity for high-compute features in the Pro tier ($200) compared to Plus ($20).</li>
            <li><strong>Evidence:</strong> Plus users get 25 Deep Research queries/mo, while Pro users get 250 queries/mo.</li>
        </ul>
    </div>

    <h2>3. Daily Token Limits</h2>
    <table>
        <thead>
            <tr>
                <th>Subscription</th>
                <th>Price</th>
                <th>Daily Tokens</th>
                <th>Derivation</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>ChatGPT Plus</strong></td>
                <td>$20</td>
                <td>8,192,000</td>
                <td>160 msgs/3hr √ó 8 windows √ó 6,400 tok</td>
            </tr>
            <tr>
                <td><strong>ChatGPT Pro</strong></td>
                <td>$200</td>
                <td>81,920,000</td>
                <td>Plus Daily Tokens √ó 10 (Linear scaling)</td>
            </tr>
            <tr>
                <td><strong>Claude Pro</strong></td>
                <td>$20</td>
                <td>640,000</td>
                <td>100 msgs/day √ó 6,400 tok</td>
            </tr>
            <tr>
                <td><strong>Gemini Advanced</strong></td>
                <td>$20</td>
                <td>640,000</td>
                <td>100 msgs/day √ó 6,400 tok</td>
            </tr>
            <tr>
                <td><strong>Claude Max 5√ó</strong></td>
                <td>$100</td>
                <td>3,200,000</td>
                <td>640,000 (Pro base) √ó 5</td>
            </tr>
            <tr>
                <td><strong>Claude Max 20√ó</strong></td>
                <td>$200</td>
                <td>12,800,000</td>
                <td>640,000 (Pro base) √ó 20</td>
            </tr>
        </tbody>
    </table>

    <div class="card">
        <h2>4. Example: Framework Desktop vs ChatGPT</h2>
        <p>Based on current inputs:</p>
        <ul>
            <li><strong>Framework Desktop (128GB):</strong> ~$3,170 USD.</li>
            <li><strong>GPT-OSS 120B local:</strong> ~33 tok/s on the Framework Desktop (community benchmark).</li>
            <li><strong>Local value:</strong> ~525K quality tokens per dollar (16h/day, 3 years).</li>
            <li><strong>ChatGPT Plus/Pro:</strong> ~11M quality tokens per dollar (same period).</li>
        </ul>
        <p>That is roughly a ~20x gap in favor of subscription today. If cloud pricing changes or local inference improves, the numbers will shift. That is why the timeline view exists: it is designed to show how value evolves over time.</p>
        <p>The purpose of this project is simple: compare how much intelligence you get per dollar across local, API, and subscription options.</p>
    </div>

    <footer style="margin-top: 4rem; font-size: 0.7rem; color: #666; text-align: center;">
        Last Updated: February 2, 2026 ‚Ä¢ LLM Value Comparison Project
    </footer>
</body>
</html>