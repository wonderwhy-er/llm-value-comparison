{
  "id": "llama-3.1-70b",
  "name": "Llama 3.1 70B",
  "provider": "Meta",
  "releaseDate": "2024-07-23",
  "modelCard": "https://ai.meta.com/blog/meta-llama-3-1/",
  
  "benchmarks": {
    "arena_elo": {
      "score": 1200,
      "source": "https://lmarena.ai/leaderboard"
    },
    "mmlu": {
      "score": 86.0,
      "source": "https://ai.meta.com/blog/meta-llama-3-1/"
    },
    "aider_polyglot": {
      "score": 32.5,
      "source": "https://aider.chat/docs/leaderboards/"
    }
  },
  
  "api": {
    "inputPer1M": 0.6,
    "outputPer1M": 0.6,
    "source": "https://www.together.ai/pricing"
  },
  
  "local": {
    "rtx_3090": {
      "tokensPerSec": 25,
      "quantization": "Q4_K_M",
      "vramRequired": 40,
      "notes": "Requires 2x RTX 3090 or offloading to RAM",
      "source": "https://github.com/ggerganov/llama.cpp/discussions/4225"
    },
    "rtx_4090": {
      "tokensPerSec": 45,
      "quantization": "Q4_K_M",
      "vramRequired": 40,
      "source": "https://github.com/ggerganov/llama.cpp/discussions"
    },
    "mac_m3_max_128gb": {
      "tokensPerSec": 18,
      "quantization": "Q4_K_M",
      "vramRequired": 45,
      "source": "https://github.com/ggerganov/llama.cpp/discussions/4167"
    }
  },
  
  "subscriptions": null
}
